# 01_4.1.2_Multiple_classes

"""
Lecture: 4_Linear_Models_for_Classification/4.1_Discriminant_Functions
Content: 01_4.1.2_Multiple_classes
"""

### 4.1.2 多类分类问题

在《模式识别与机器学习》（PRML）一书的第4章中，Bishop博士详细介绍了线性分类模型的概念。第4.1节专注于判别函数，并在4.1.2节中讨论了多类分类问题。以下是对4.1.2节内容的详细分析。

#### 多类分类

对于多类分类问题，我们需要扩展线性判别函数，以处理多个类别 $ K $。最直接的方法是组合多个两类判别函数，但这种方法存在一些严重的问题。

##### 一对其余分类器（One-versus-the-Rest Classifier）

首先，我们可以使用 $ K-1 $ 个分类器，每个分类器解决一个特定类别 $ C_k $ 与非该类别的点的分类问题。这种方法称为“一对其余”分类器。图4.2左侧显示了一个示例，其中该方法导致输入空间中的某些区域分类不明确。

##### 一对一分类器（One-versus-One Classifier）

另一种方法是引入 $ K(K-1)/2 $ 个二元判别函数，每个函数用于每对可能的类别。这种方法称为“一对一”分类器。然后，根据判别函数的多数投票对每个点进行分类。然而，这种方法同样会遇到分类不明确的问题，如图4.2右侧所示。

##### 单一 K 类判别函数（Single K-Class Discriminant Function）

为了避免这些困难，我们可以考虑一个单一的 $ K $ 类判别函数，其中包含 $ K $ 个线性函数：

$$ y_k(\mathbf{x}) = \mathbf{w}_k^T \mathbf{x} + w_{k0} $$

然后，如果 $ y_k(\mathbf{x}) > y_j(\mathbf{x}) $ 对所有 $ j \neq k $ 成立，则将点 $ \mathbf{x} $ 分配到类 $ C_k $。类 $ C_k $ 和类 $ C_j $ 之间的决策边界由 $ y_k(\mathbf{x}) = y_j(\mathbf{x}) $ 定义，因此对应于一个 $ (D-1) $ 维超平面，其定义如下：

$$ (\mathbf{w}_k - \mathbf{w}_j)^T \mathbf{x} + (w_{k0} - w_{j0}) = 0 $$

这与第4.1.1节讨论的两类情况下的决策边界形式相同，因此适用类似的几何属性。

##### 决策区域的几何属性

这种判别函数的决策区域总是单连通和凸的。

### 结论

在第4.1.2节中，Bishop博士详细阐述了多类分类问题中的线性判别函数。为了有效处理多类分类问题，可以使用单一的 $ K $ 类判别函数，而不是简单地组合多个两类判别函数。这种方法不仅可以避免分类不明确的问题，还能确保决策区域的单连通性和凸性。这部分内容为后续章节中讨论更复杂的非线性分类方法奠定了基础。