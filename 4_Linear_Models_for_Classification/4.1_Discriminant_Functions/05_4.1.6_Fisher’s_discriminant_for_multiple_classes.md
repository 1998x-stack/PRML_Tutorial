# 05_4.1.6_Fisher’s_discriminant_for_multiple_classes

"""
Lecture: 4_Linear_Models_for_Classification/4.1_Discriminant_Functions
Content: 05_4.1.6_Fisher’s_discriminant_for_multiple_classes
"""

## 探索PRML.pdf中的知识

PRML (Pattern Recognition and Machine Learning) 是Christopher M. Bishop所著的一本经典教材，涵盖了模式识别和机器学习领域的核心知识。在本书中，第4章介绍了线性分类模型，包括判别函数、最小二乘法分类、Fisher线性判别、感知器算法等。在第4.1.6节中，作者详细讨论了多类Fisher线性判别的方法。

### 第4.1.6节：多类Fisher线性判别

在这一节中，作者探讨了将Fisher线性判别法推广到多类分类问题的思路。通过引入多个线性“特征”，并使用特征值分解的方法，作者展示了如何在多类分类问题中应用Fisher判别法。

## 深入分析

### 背景介绍

Fisher线性判别（Fisher's Linear Discriminant, FLD）是一种用于寻找能够最大化类间方差和最小化类内方差的投影方向的技术。在二类分类问题中，FLD可以通过投影数据到一维空间来最大化两类之间的距离，同时最小化每类内部的散布。然而，在多类分类问题中，需要对这种方法进行推广，以处理多个类别之间的分类。

### 多类Fisher线性判别的步骤

1. **线性特征的引入**：
   - 对于多类分类问题，我们假设输入空间的维数 $D$ 大于类的数量 $K$。接下来，我们引入 $D' > 1$ 个线性“特征” $y_k = w_k^T x$，其中 $k = 1, \ldots, D'$。
   - 这些特征值可以组合在一起形成一个向量 $y$。类似地，权重向量 $\{w_k\}$ 可以看作是矩阵 $W$ 的列，从而有：
     $$
     y = W^T x
     $$
   - 这里我们不包含偏置参数。

2. **类内协方差矩阵的推广**：
   - 类内协方差矩阵 $S_W$ 的推广形式如下：
     $$
     S_W = \sum_{k=1}^{K} S_k
     $$
   - 其中，$S_k$ 表示第 $k$ 类的协方差矩阵：
     $$
     S_k = \sum_{n \in C_k} (x_n - m_k)(x_n - m_k)^T
     $$
   - 这里 $m_k$ 是第 $k$ 类的均值向量，定义为：
     $$
     m_k = \frac{1}{N_k} \sum_{n \in C_k} x_n
     $$
     $N_k$ 是第 $k$ 类中的样本数量。

3. **类间协方差矩阵的推广**：
   - 总协方差矩阵 $S_T$ 可以表示为：
     $$
     S_T = \sum_{n=1}^{N} (x_n - m)(x_n - m)^T
     $$
   - 其中 $m$ 是总数据集的均值：
     $$
     m = \frac{1}{N} \sum_{n=1}^{N} x_n = \frac{1}{N} \sum_{k=1}^{K} N_k m_k
     $$
   - 总协方差矩阵可以分解为类内协方差矩阵和类间协方差矩阵之和：
     $$
     S_T = S_W + S_B
     $$
   - 类间协方差矩阵 $S_B$ 定义为：
     $$
     S_B = \sum_{k=1}^{K} N_k (m_k - m)(m_k - m)^T
     $$

4. **特征值分解**：
   - 我们的目标是找到投影矩阵 $W$，使得投影后的数据在类间有最大的方差，同时在类内有最小的方差。
   - 为此，我们最大化如下目标函数：
     $$
     J(W) = \mathrm{Tr} \left( (W^T S_W W)^{-1} (W^T S_B W) \right)
     $$
   - 这一目标可以通过求解如下特征值问题来实现：
     $$
     S_W^{-1} S_B w = \lambda w
     $$
   - 其中，$w$ 是特征向量，$\lambda$ 是特征值。选择对应最大特征值的特征向量作为投影矩阵的列。

### 结论

通过以上分析可以看出，Fisher线性判别法在处理多类分类问题时，通过引入多个线性特征，并通过特征值分解的方法，可以有效地找到投影矩阵，使得投影后的数据在类间方差最大，类内方差最小。这种方法为多类分类问题提供了一种有效的解决方案，有助于在实际应用中提高分类模型的性能。

这种分析为理解不同机器学习方法之间的关系提供了有价值的视角，有助于我们在实际应用中选择合适的模型和算法。