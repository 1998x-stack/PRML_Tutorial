# 02_4.3.3_Iterative_reweighted_least_squares

"""
Lecture: 4_Linear_Models_for_Classification/4.3_Probabilistic_Discriminative_Models
Content: 02_4.3.3_Iterative_reweighted_least_squares
"""

### 详解PRML中的4.3.3节：迭代重加权最小二乘法

《模式识别与机器学习》（Pattern Recognition and Machine Learning, PRML）是由Christopher M. Bishop所著的一本经典教材，其中第4章涵盖了线性分类模型的内容。在第4.3节，作者介绍了概率判别模型（Probabilistic Discriminative Models）。具体来说，第4.3.3节探讨了迭代重加权最小二乘法（Iterative Reweighted Least Squares, IRLS）。以下是对这一节内容的详细分析。

### 迭代重加权最小二乘法的背景

在线性回归模型中，假设高斯噪声模型的最大似然解具有闭式解，这是由于对数似然函数相对于参数向量 $w$ 的二次依赖性。对于逻辑回归，由于逻辑Sigmoid函数的非线性，已不存在闭式解。然而，对数似然函数的偏离二次形式并不显著，误差函数是凹的，因此具有唯一最小值。误差函数可以通过一种基于牛顿-拉弗森迭代优化方案的高效迭代技术来最小化，该方案使用对数似然函数的局部二次近似。

### 牛顿-拉弗森方法

牛顿-拉弗森更新公式用于最小化函数 $E(w)$，其形式为：

$$ w_{\text{new}} = w_{\text{old}} - H^{-1} \nabla E(w) $$

其中，$H$ 是Hessian矩阵，其元素包括 $E(w)$ 关于 $w$ 分量的二阶导数。

#### 应用于线性回归模型

对于线性回归模型，误差函数的梯度和Hessian为：

$$ \nabla E(w) = \sum_{n=1}^{N} (w^T \phi_n - t_n) \phi_n = \Phi^T \Phi w - \Phi^T t $$

$$ H = \nabla \nabla E(w) = \sum_{n=1}^{N} \phi_n \phi_n^T = \Phi^T \Phi $$

牛顿-拉弗森更新公式为：

$$ w_{\text{new}} = w_{\text{old}} - (\Phi^T \Phi)^{-1} (\Phi^T \Phi w_{\text{old}} - \Phi^T t) = (\Phi^T \Phi)^{-1} \Phi^T t $$

这与标准的最小二乘解相同，因为误差函数在这种情况下是二次的，因此牛顿-拉弗森公式在一步中给出了确切解。

#### 应用于逻辑回归模型

对于逻辑回归模型，交叉熵误差函数的梯度和Hessian为：

$$ \nabla E(w) = \sum_{n=1}^{N} (y_n - t_n) \phi_n = \Phi^T (y - t) $$

$$ H = \nabla \nabla E(w) = \sum_{n=1}^{N} y_n (1 - y_n) \phi_n \phi_n^T = \Phi^T R \Phi $$

其中，$y_n$ 是逻辑回归模型的预测，$R$ 是对角矩阵，其元素为：

$$ R_{nn} = y_n (1 - y_n) $$

牛顿-拉弗森更新公式为：

$$ w_{\text{new}} = w_{\text{old}} - (\Phi^T R \Phi)^{-1} \Phi^T (y - t) = (\Phi^T R \Phi)^{-1} \Phi^T R z $$

其中，$z$ 是一个N维向量，其元素为：

$$ z = \Phi w_{\text{old}} - R^{-1} (y - t) $$

### 迭代重加权最小二乘法（IRLS）

IRLS算法用于逻辑回归中，通过迭代更新权重向量 $w$，每次使用新的权重向量 $w$ 计算修正后的加权矩阵 $R$。因此，IRLS算法被称为迭代重加权最小二乘法。

### IRLS的优势

1. **收敛速度快**：由于IRLS使用了Hessian矩阵的二阶信息，通常比简单的梯度下降法收敛更快。
2. **唯一最小值**：误差函数是凹的，因此IRLS方法能找到全局最小值。
3. **适用于广泛的问题**：除了逻辑回归，IRLS还可以应用于其他广泛的广义线性模型。

### 结论

通过以上分析可以看出，迭代重加权最小二乘法是一种高效的优化方法，尤其适用于逻辑回归等广义线性模型。它利用牛顿-拉弗森方法，通过迭代更新参数，使得模型能快速收敛到全局最小值。掌握IRLS方法的理论和应用，有助于我们在实际问题中选择合适的模型和算法，提高分类和预测的准确性。