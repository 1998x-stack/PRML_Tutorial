# 03_5.5.4_Tangent_propagation

"""
Lecture: 5_Neural_Networks/5.5_Regularization_in_Neural_Networks
Content: 03_5.5.4_Tangent_propagation
"""

### 5.5.4 切线传播 (Tangent Propagation)

#### 背景和动机

在神经网络中，正则化（Regularization）技术用于减少过拟合，提高模型的泛化能力。切线传播是一种通过鼓励模型对输入变换保持不变性来实现正则化的方法。这种方法最早由Simard等人（1992）提出。它通过引入一个额外的正则项来使得模型的输出对输入的微小变换不敏感，从而增强模型的鲁棒性和泛化能力。

#### 基本原理

考虑对一个特定的输入向量 $ \mathbf{x}_n $ 进行变换的效果。假设变换是连续的，例如平移或旋转，而不是镜像反射等不连续变换。那么，变换后的模式将在 $ D $ 维输入空间中扫出一个流形 $ M $。为了简化讨论，我们假设 $ D = 2 $。如图5.15所示，若变换由单一参数 $ \xi $ 控制（如旋转角度），则 $ \mathbf{x}_n $ 扫出的子空间 $ M $ 是一维的，并由 $ \xi $ 参数化。设由此变换作用于 $ \mathbf{x}_n $ 得到的向量记为 $ \mathbf{s}(\mathbf{x}_n, \xi) $，定义为 $ \mathbf{s}(\mathbf{x}, 0) = \mathbf{x} $。则流形 $ M $ 的切线由方向导数 $ \tau = \frac{\partial \mathbf{s}}{\partial \xi} $ 给出，在点 $ \mathbf{x}_n $ 处的切向量为：

$$ \tau_n = \left. \frac{\partial \mathbf{s}(\mathbf{x}_n, \xi)}{\partial \xi} \right|_{\xi=0} $$

在输入向量的变换下，网络的输出向量通常会发生变化。输出 $ k $ 对 $ \xi $ 的导数为：

$$ \left. \frac{\partial y_k}{\partial \xi} \right|_{\xi=0} = \sum_{i=1}^{D} \frac{\partial y_k}{\partial x_i} \frac{\partial x_i}{\partial \xi} \Bigg|_{\xi=0} = \sum_{i=1}^{D} J_{ki} \tau_i $$

其中 $ J_{ki} $ 是雅可比矩阵 $ J $ 的 $ (k, i) $ 元素。这个结果可以用于修改标准误差函数，以鼓励数据点邻域内的局部不变性，通过将正则化函数 $ \Omega $ 加到原始误差函数 $ E $ 中，得到总误差函数：

$$ \tilde{E} = E + \lambda \Omega $$

其中 $ \lambda $ 是正则化系数，正则化函数 $ \Omega $ 为：

$$ \Omega = \frac{1}{2} \sum_{n} \sum_{k} \left( \left. \frac{\partial y_{nk}}{\partial \xi} \right|_{\xi=0} \right)^2 = \frac{1}{2} \sum_{n} \sum_{k} \left( \sum_{i=1}^{D} J_{nki} \tau_{ni} \right)^2 $$

当网络映射函数在每个模式向量的邻域内在变换下不变时，正则化函数为零。参数 $ \lambda $ 决定了拟合训练数据和学习不变性属性之间的平衡。

#### 实现细节

在实际实现中，可以使用有限差分法来近似切向量 $ \tau_n $。通过用小值 $ \xi $ 变换后的相应向量减去原始向量 $ \mathbf{x}_n $，再除以 $ \xi $：

$$ \tau_n \approx \frac{\mathbf{s}(\mathbf{x}_n, \xi) - \mathbf{x}_n}{\xi} $$

如图5.16所示，通过这种方式可以计算切向量。

正则化函数依赖于通过雅可比矩阵 $ J $ 计算得到的网络权重。可以通过扩展反向传播算法来计算正则化项对网络权重的导数。

如果变换由 $ L $ 个参数控制（例如二维图像中的平移和旋转组合时 $ L = 3 $），则流形 $ M $ 的维度为 $ L $，对应的正则化项由类似于公式（5.128）形式的多个项之和给出，每个变换一个项。如果同时考虑多个变换，并使得网络映射分别对每个变换不变，则网络映射在变换组合下将（局部）不变。

#### 相关技术和扩展

与切线传播相关的技术还有切线距离（Tangent Distance），它可用于将不变性属性构建到基于距离的方法中，例如最近邻分类器。训练时使用变换后的数据也可以通过扩展训练集来鼓励模型对一组变换保持不变。这种方法与切线传播技术密切相关，并且在适当情况下也可以显著提高泛化能力，尽管其计算成本较高。