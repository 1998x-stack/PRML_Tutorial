# 01_6.4.2_Gaussian_processes_for_regression

"""
Lecture: 6_Kernel_Methods/6.4_Gaussian_Processes
Content: 01_6.4.2_Gaussian_processes_for_regression
"""

## 详细分析第6.4.2节：用于回归的高斯过程

### 引言
高斯过程（Gaussian Processes, GPs）是一种非参数贝叶斯方法，用于建模和预测函数分布。与传统回归方法不同，高斯过程可以提供预测的不确定性量化。第6.4.2节详细介绍了高斯过程在回归任务中的应用。

### 高斯过程回归的基本概念
高斯过程假设目标函数 $ f(x) $ 服从一个高斯过程，其形式为：
$$ f(x) \sim \mathcal{GP}(m(x), k(x, x')) $$
其中，$ m(x) $ 是均值函数，通常设为0，$ k(x, x') $ 是协方差函数（或核函数），定义了输入点之间的相似性。

### 核函数的选择
核函数是高斯过程的核心，常见的核函数包括：
1. **线性核**：
   $$ k(x, x') = x^T x' $$
2. **高斯核**（RBF核）：
   $$ k(x, x') = \exp \left( -\frac{\|x - x'\|^2}{2l^2} \right) $$
3. **多项式核**：
   $$ k(x, x') = (x^T x' + c)^d $$

### 训练数据的联合分布
给定训练数据集 $\{(x_n, t_n)\}_{n=1}^{N}$，目标变量的联合分布为：
$$ p(t|X) = \mathcal{N}(0, K + \sigma^2 I) $$
其中，$ K $ 是核矩阵，$ K_{ij} = k(x_i, x_j) $，$ \sigma^2 $ 是噪声方差。

### 预测分布
对于新的输入 $ x_* $，预测分布也是高斯分布，其均值和协方差分别为：
$$ \mu_* = k_*^T (K + \sigma^2 I)^{-1} t $$
$$ \sigma^2_* = k(x_*, x_*) - k_*^T (K + \sigma^2 I)^{-1} k_* $$
其中，$ k_* $ 是新的输入与训练数据之间的核向量。

### 实例分析
假设我们有一个一维回归问题，输入变量为 $ x $，目标变量为 $ t $。生成数据如下：
$$ x_i \sim \mathcal{U}(0, 10) $$
$$ t_i = \sin(x_i) + \epsilon_i $$
其中，$ \epsilon_i \sim \mathcal{N}(0, 0.1) $。

#### 数据可视化
绘制输入 $ x $ 和目标 $ t $ 的散点图。

#### 训练高斯过程模型
1. **构建核矩阵** $ K $。
2. **计算预测均值和方差**。

#### 结果分析
通过可视化预测均值和方差，可以看到高斯过程模型不仅捕捉了数据的非线性关系，还量化了预测的不确定性。

### 高斯过程回归的优势
- **非参数性**：高斯过程不假设数据的分布形式，适用于多种复杂的分布情况。
- **不确定性量化**：通过预测分布的方差，高斯过程可以量化预测的不确定性。
- **灵活性**：可以通过选择不同的核函数来适应不同的应用场景。

### 结论
高斯过程回归通过引入核函数，提供了一种灵活且强大的方法来建模复杂的函数关系，并有效量化预测的不确定性。这使得高斯过程在处理非线性和高噪声数据时表现出色。
