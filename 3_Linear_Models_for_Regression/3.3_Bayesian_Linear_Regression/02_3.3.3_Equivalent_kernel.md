# 02_3.3.3_Equivalent_kernel

"""
Lecture: 3_Linear_Models_for_Regression/3.3_Bayesian_Linear_Regression
Content: 02_3.3.3_Equivalent_kernel
"""

## 3.3.3 等效核

### 概述
在贝叶斯线性回归模型中，我们得到了参数 $ w $ 的后验均值解。在这一节中，我们将探索这种解的等效核表示，它为内核方法（包括高斯过程）奠定了基础。

### 后验均值解
线性基函数模型的后验均值解 $ m_N $ 可以写成如下形式：

$$ m_N = \beta S_N \Phi^T t $$

将其代入预测均值表达式中，我们得到：

$$ y(x, m_N) = m_N^T \phi(x) = \beta \phi(x)^T S_N \Phi^T t $$

其中， $ S_N $ 由以下公式定义：

$$ S_N = (\alpha I + \beta \Phi^T \Phi)^{-1} $$

### 预测均值的等效核表示
通过代入并整理，我们可以将预测均值写成以下形式：

$$ y(x, m_N) = \sum_{n=1}^N k(x, x_n) t_n $$

其中，等效核函数 $ k(x, x') $ 定义为：

$$ k(x, x') = \beta \phi(x)^T S_N \phi(x') $$

这种形式的预测函数通过将训练集目标值的线性组合来进行预测，被称为线性平滑器。等效核依赖于数据集中的输入值 $ x_n $，因为它们出现在 $ S_N $ 的定义中。

### 等效核的性质
等效核 $ k(x, x') $ 对于高斯基函数的情况进行了可视化，如图3.10所示。核函数 $ k(x, x') $ 对三个不同的 $ x $ 值进行了绘制，可以看到它们在 $ x $ 附近是局部化的。因此，预测分布在 $ x $ 处的均值 $ y(x, m_N) $ 是通过形成目标值的加权组合得到的，其中距离 $ x $ 较近的数据点权重大于较远的数据点。

这种局部化特性不仅适用于局部高斯基函数，对于非局部多项式和S形基函数也同样适用，如图3.11所示。

### 进一步理解
通过考虑 $ y(x) $ 和 $ y(x') $ 之间的协方差，可以进一步理解等效核的作用，协方差由以下公式给出：

$$ \text{cov}[y(x), y(x')] = \phi(x)^T S_N \phi(x') = \beta^{-1} k(x, x') $$

从等效核的形式可以看出，相邻点的预测均值高度相关，而距离较远的点的相关性较小。

### 结论
等效核的概念为内核方法提供了基础，使我们能够直接在内核函数的基础上进行回归分析，而无需显式地引入特征向量 $ \phi(x) $。这为处理高维甚至无限维特征空间提供了可能性。

### 示例代码
以下是实现等效核的Python代码：

```python
import numpy as np
from scipy.linalg import inv

class BayesianLinearRegression:
    """
    贝叶斯线性回归模型类

    参数:
        alpha (float): 先验分布的方差参数
        beta (float): 噪声精度参数
    """
    
    def __init__(self, alpha: float, beta: float):
        """
        初始化贝叶斯线性回归模型

        参数:
            alpha (float): 先验分布的方差参数
            beta (float): 噪声精度参数
        """
        self.alpha = alpha
        self.beta = beta
        self.m_N = None
        self.S_N = None

    def fit(self, X: np.ndarray, t: np.ndarray):
        """
        拟合贝叶斯线性回归模型

        参数:
            X (np.ndarray): 输入数据矩阵
            t (np.ndarray): 目标值向量
        """
        # 添加偏置项
        X = np.hstack([np.ones((X.shape[0], 1)), X])
        
        # 计算先验分布的协方差矩阵
        S_0_inv = self.alpha * np.eye(X.shape[1])
        
        # 计算后验分布的协方差矩阵
        self.S_N = inv(S_0_inv + self.beta * X.T @ X)
        
        # 计算后验分布的均值向量
        self.m_N = self.beta * self.S_N @ X.T @ t
        
        print(f"后验均值向量: {self.m_N}")
        print(f"后验协方差矩阵: {self.S_N}")

    def predict(self, X_new: np.ndarray):
        """
        使用贝叶斯线性回归模型进行预测

        参数:
            X_new (np.ndarray): 新的输入数据矩阵

        返回:
            均值预测值和预测方差
        """
        # 添加偏置项
        X_new = np.hstack([np.ones((X_new.shape[0], 1)), X_new])
        
        # 预测均值
        y_mean = X_new @ self.m_N
        
        # 预测方差
        y_var = 1 / self.beta + np.sum(X_new @ self.S_N * X_new, axis=1)
        
        return y_mean, y_var

    def equivalent_kernel(self, X_new: np.ndarray):
        """
        计算等效核

        参数:
            X_new (np.ndarray): 新的输入数据矩阵

        返回:
            等效核矩阵
        """
        X_new = np.hstack([np.ones((X_new.shape[0], 1)), X_new])
        kernel = self.beta * X_new @ self.S_N @ X_new.T
        return kernel

if __name__ == "__main__":
    # 示例数据
    X_train = np.array([[0.1], [0.4], [0.7], [1.0]])
    t_train = np.array([1.1, 1.9, 3.0, 4.2])
    
    model = BayesianLinearRegression(alpha=1.0, beta=25.0)
    model.fit(X_train, t_train)
    
    # 新数据进行预测
    X_new = np.array([[0.2], [0.5], [0.8]])
    y_mean, y_var = model.predict(X_new)
    kernel = model.equivalent_kernel(X_new)
    
    print("预测均值: ", y_mean)
    print("预测方差: ", y_var)
    print("等效核矩阵: ", kernel)
```

### 代码解释
1. **类定义**:
    - `BayesianLinearRegression` 类用于实现贝叶斯线性回归模型。
    - 初始化时需要指定先验分布的方差参数 `alpha` 和噪声精度参数 `beta`。
2. **拟合模型**:
    - `fit` 方法用于拟合模型，计算后验分布的均值向量 `m_N` 和协方差矩阵 `S_N`。
3. **预测**:
    - `predict` 方法使用拟合好的模型对新的输入数据进行预测，返回预测的均值和方差。
4. **等效核**:
    - `equivalent_kernel` 方法计算等效核矩阵，用于理解输入数据点之间的关系。
5. **示例**:
    - 在 `__main__` 中，通过示例数据演示了模型的拟合、预测和等效核计算过程。

### 检查代码逻辑
- 使用 `np.hstack` 添加偏置项，确保输入数据包含截距。
- 使用矩阵运算和线性代数库确保计算的准确性和高效性。
- 通过打印重要信息（如后验均值向量和协方差矩阵）来验证模型的正确性。