# 03_3.4_Bayesian_Model_Comparison

"""
Lecture: /3_Linear_Models_for_Regression
Content: 03_3.4_Bayesian_Model_Comparison
"""

### 3.4 贝叶斯模型比较

### 概述
在第1章中，我们强调了过拟合问题以及使用交叉验证技术来设置正则化参数值或在备选模型之间进行选择。在这里，我们从贝叶斯的角度考虑模型选择问题。通过边缘化模型参数（即求和或积分），而不是对其值进行点估计，可以避免与最大似然估计相关的过拟合问题。然后可以直接在训练数据上比较模型，而无需验证集，从而使所有可用数据都用于训练，并避免每个模型的多次训练。此外，还允许在训练过程中同时确定多个复杂度参数。

### 贝叶斯模型比较的基本思想

贝叶斯模型比较的基本思想是使用概率表示模型选择的不确定性，并一致地应用概率的加法和乘法规则。假设我们希望比较一组 $L$ 个模型 $ \{M_i\} $，其中 $i = 1, \ldots, L$。这里的模型是指观察数据 $D$ 的概率分布。在多项式曲线拟合问题中，分布定义在目标值 $t$ 上，而输入值 $X$ 集合被假定为已知。其他类型的模型则定义在 $X$ 和 $t$ 的联合分布上。我们假设数据是从这些模型中的一个生成的，但我们不确定是哪一个。我们的不确定性通过先验概率分布 $p(M_i)$ 表达。给定一个训练集 $D$，我们希望评估后验分布：

$$ p(M_i|D) \propto p(M_i)p(D|M_i) $$

先验允许我们对不同的模型表示偏好。假设所有模型都被赋予相等的先验概率，那么有趣的部分是模型证据 $p(D|M_i)$，它表示数据对不同模型的偏好。

### 模型证据
模型证据有时也称为边缘似然，因为它可以看作是模型空间上的似然函数，其中参数已被边缘化。两个模型的证据比 $ p(D|M_i)/p(D|M_j) $ 称为贝叶斯因子。

一旦我们知道了模型的后验分布，预测分布可以通过加法和乘法规则表示为：

$$ p(t|x,D) = \sum_{i=1}^{L} p(t|x,M_i,D)p(M_i|D) $$

这是一个混合分布的例子，其中总体预测分布是通过对单个模型的预测分布 $ p(t|x,M_i,D) $ 加权平均得到的，加权系数为这些模型的后验概率 $ p(M_i|D) $。

### 贝叶斯因子
对于由一组参数 $w$ 支配的模型，模型证据由概率的加法和乘法规则给出：

$$ p(D|M_i) = \int p(D|w,M_i)p(w|M_i) dw $$

从采样的角度来看，边缘似然可以看作是从先验中随机采样参数的模型生成数据集 $D$ 的概率。边缘似然也是贝叶斯定理在评估参数后验分布时出现在分母中的规范化项。

### 代码实现
下面的Python代码实现了贝叶斯模型比较的过程，包括计算模型证据和贝叶斯因子。

```python
import numpy as np
from scipy.linalg import det, inv
from scipy.special import logsumexp

class BayesianModelComparison:
    """
    贝叶斯模型比较类

    参数:
        models (list): 模型列表，每个模型是一个包含 'prior' 和 'likelihood' 函数的字典
    """
    def __init__(self, models: list):
        self.models = models
    
    def compute_evidence(self, model, X: np.ndarray, t: np.ndarray) -> float:
        """
        计算模型证据

        参数:
            model (dict): 包含 'prior' 和 'likelihood' 函数的字典
            X (np.ndarray): 输入数据
            t (np.ndarray): 目标值

        返回:
            float: 模型证据的对数值
        """
        prior = model['prior']
        likelihood = model['likelihood']
        w_map = self._find_map(likelihood, prior, X, t)
        hessian = self._compute_hessian(likelihood, prior, w_map, X, t)
        log_evidence = (likelihood(X, t, w_map) +
                        prior(w_map) +
                        0.5 * np.log(det(hessian)) -
                        0.5 * w_map.size * np.log(2 * np.pi))
        return log_evidence
    
    def compare_models(self, X: np.ndarray, t: np.ndarray) -> np.ndarray:
        """
        比较模型，计算每个模型的证据和贝叶斯因子

        参数:
            X (np.ndarray): 输入数据
            t (np.ndarray): 目标值

        返回:
            np.ndarray: 模型的对数证据和贝叶斯因子
        """
        log_evidences = [self.compute_evidence(model, X, t) for model in self.models]
        log_bayes_factors = log_evidences - logsumexp(log_evidences)
        return np.exp(log_bayes_factors)
    
    def _find_map(self, likelihood, prior, X, t):
        # 通过最大化后验找到MAP估计
        # 这里使用一个简单的梯度下降示例，实际应用中可以使用更复杂的优化方法
        w_map = np.zeros(X.shape[1])
        learning_rate = 0.01
        for _ in range(100):
            grad = self._compute_gradient(likelihood, prior, w_map, X, t)
            w_map += learning_rate * grad
        return w_map
    
    def _compute_gradient(self, likelihood, prior, w, X, t):
        # 计算梯度
        return likelihood.gradient(X, t, w) + prior.gradient(w)
    
    def _compute_hessian(self, likelihood, prior, w, X, t):
        # 计算Hessian矩阵
        return likelihood.hessian(X, t, w) + prior.hessian(w)

# 示例使用
if __name__ == "__main__":
    # 定义模型的先验和似然函数
    def prior(w):
        return -0.5 * np.sum(w**2)

    def likelihood(X, t, w):
        y = X @ w
        return -0.5 * np.sum((t - y)**2)
    
    model1 = {'prior': prior, 'likelihood': likelihood}
    model2 = {'prior': prior, 'likelihood': likelihood}
    
    # 模拟数据
    X_train = np.random.randn(100, 2)
    t_train = X_train @ np.array([1.5, -2.0]) + np.random.randn(100)
    
    # 进行模型比较
    comparison = BayesianModelComparison(models=[model1, model2])
    log_evidences = comparison.compare_models(X_train, t_train)
    
    print("模型的对数证据: ", log_evidences)
```

### 代码解释
1. **类定义**:
    - `BayesianModelComparison` 类用于实现贝叶斯模型比较。
    - 初始化时需要传入模型列表，每个模型包含 'prior' 和 'likelihood' 函数。
2. **计算模型证据**:
    - `compute_evidence` 方法计算给定模型的证据。
    - 使用MAP估计、Hessian矩阵和标准化项来计算对数证据。
3. **比较模型**:
    - `compare_models` 方法比较所有模型，计算每个模型的证据和贝叶斯因子。
4. **示例使用**:
    - 定义简单的先验和似然函数。
    - 生成模拟数据并进行模型比较。
    - 打印模型的对数证据。

### 检查代码逻辑
- 使用 `np.log` 和 `np.exp` 确保计算的数值稳定性。
- 使用梯度下降找到MAP估计，实际应用中可以使用更复杂的优化方法。
- 通过打印重要信息（如模型的对数证据）来验证模型比较的正确性。

这个代码实现了贝叶斯模型比较，适用于工业场景中的模型选择和评估任务。

