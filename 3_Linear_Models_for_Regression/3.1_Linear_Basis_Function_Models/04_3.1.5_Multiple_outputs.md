# 04_3.1.5_Multiple_outputs

"""
Lecture: 3_Linear_Models_for_Regression/3.1_Linear_Basis_Function_Models
Content: 04_3.1.5_Multiple_outputs
"""

### 探索 PDF

从 PDF 文档中，我找到了 "3.1.5 Multiple Outputs" 部分的内容。下面是详细的内容：

### 3.1.5 多输出 (Multiple Outputs)

到目前为止，我们只考虑了单一目标变量 $ t $ 的情况。在一些应用中，我们可能希望预测 $ K > 1 $ 个目标变量，这些变量我们集体称为目标向量 $ t $。这可以通过为 $ t $ 的每个分量引入不同的一组基函数来实现，从而导致多个独立的回归问题。然而，更有趣且更常见的方法是使用相同的一组基函数来建模目标向量的所有分量，这样：
$$ y(x, w) = W^T \phi(x) $$
其中 $ y $ 是一个 $ K $ 维列向量，$ W $ 是一个 $ M \times K $ 的参数矩阵，$ \phi(x) $ 是一个 $ M $ 维列向量，其元素为 $ \phi_j(x) $，其中 $ \phi_0(x) = 1 $ 如前所述。假设我们取目标向量的条件分布为形式如下的各向同性高斯分布：
$$ p(t | x, W, \beta) = N(t | W^T \phi(x), \beta^{-1}I) $$
如果我们有一组观测值 $ t_1, \ldots, t_N $，我们可以将这些观测值组合成一个 $ N \times K $ 的矩阵 $ T $，使得第 $ n $ 行由 $ t_n^T $ 给出。同样，我们可以将输入向量 $ x_1, \ldots, x_N $ 组合成一个矩阵 $ X $。则对数似然函数为：
$$ \ln p(T | X, W, \beta) = \sum_{n=1}^N \ln N(t_n | W^T \phi(x_n), \beta^{-1}I) = \frac{NK}{2} \ln \left( \frac{\beta}{2\pi} \right) - \frac{\beta}{2} \sum_{n=1}^N \| t_n - W^T \phi(x_n) \|^2 $$

和之前一样，我们可以对 $ W $ 最大化该函数，得到：
$$ W_{ML} = (\Phi^T \Phi)^{-1} \Phi^T T $$

如果我们检查每个目标变量 $ t_k $ 的结果，我们有：
$$ w_k = (\Phi^T \Phi)^{-1} \Phi^T t_k = \Phi^\dagger t_k $$
其中 $ t_k $ 是一个 $ N $ 维列向量，其分量为 $ t_{nk} $，其中 $ n = 1, \ldots, N $。因此，回归问题的解在不同的目标变量之间解耦，我们只需要计算一个伪逆矩阵 $ \Phi^\dagger $，该矩阵由所有向量 $ w_k $ 共享。

扩展到具有任意协方差矩阵的通用高斯噪声分布是直截了当的。同样，这导致 $ K $ 个独立的回归问题的解耦。这一结果并不令人意外，因为参数 $ W $ 只定义了高斯噪声分布的均值，并且我们从 2.3.4 节知道，多元高斯均值的最大似然解与协方差无关 。

### 极其详细的分析

在多输出模型中，我们使用相同的基函数集合来对所有目标变量的分量进行建模，这样做的目的是为了捕捉目标变量之间的共同模式，而不仅仅是独立地预测每个目标变量。我们将目标变量表示为列向量 $ t $，基函数表示为 $ \phi(x) $，参数矩阵表示为 $ W $。通过这种方法，我们可以将输入向量 $ x $ 转换为目标向量 $ y $，并假设目标向量的条件分布服从高斯分布。

在计算过程中，我们将所有观测值 $ t_1, \ldots, t_N $ 组合成矩阵 $ T $，并将输入向量组合成矩阵 $ X $。然后，我们通过最大化对数似然函数来估计参数矩阵 $ W $。这种方法的一个重要优势是，它将多输出回归问题解耦为多个独立的回归问题，这简化了计算过程。对于每个目标变量，我们只需要计算一个伪逆矩阵 $ \Phi^\dagger $，这显著减少了计算复杂度。

这种方法在许多实际应用中非常有用，例如多变量时间序列预测、多标签分类等。在这些应用中，各个目标变量之间往往存在一定的相关性，使用相同的基函数集合可以更好地捕捉这些相关性，提高预测精度。

### Python代码示例

下面是一个使用 NumPy 和 SciPy 从头实现的多输出回归模型的 Python 代码示例：

```python
import numpy as np
from numpy.linalg import inv

class MultipleOutputRegression:
    def __init__(self, basis_functions: int):
        """
        初始化多输出回归模型。

        参数:
        basis_functions (int): 基函数的数量。
        """
        self.basis_functions = basis_functions
        self.W = None

    def fit(self, X: np.ndarray, T: np.ndarray):
        """
        训练多输出回归模型。

        参数:
        X (np.ndarray): 输入矩阵，形状为 (N, D)。
        T (np.ndarray): 目标矩阵，形状为 (N, K)。
        """
        N, D = X.shape
        N, K = T.shape

        # 扩展输入矩阵以包含基函数
        Phi = self._design_matrix(X)

        # 计算伪逆矩阵
        Phi_T_Phi_inv = inv(Phi.T @ Phi)
        self.W = Phi_T_Phi_inv @ Phi.T @ T

    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        使用训练好的模型进行预测。

        参数:
        X (np.ndarray): 输入矩阵，形状为 (N, D)。

        返回:
        np.ndarray: 预测结果，形状为 (N, K)。
        """
        Phi = self._design_matrix(X)
        return Phi @ self.W

    def _design_matrix(self, X: np.ndarray) -> np.ndarray:
        """
        生成设计矩阵，包含基函数。

        参数:
        X (np.ndarray): 输入矩阵，形状为 (N, D)。

        返回:
        np.ndarray: 设计矩阵，形状为 (N, M)。
        """
        N, D = X.shape
        Phi = np.ones((N, self.basis_functions))
        for i in range(1, self.basis_functions):
            Phi[:, i] = X[:, 0] ** i  # 示例：多项式基函数
        return Phi

# 示例使用
if __name__ == "__main__":
    # 生成示例数据
    X = np.random.rand(100, 1)
    T = np.hstack((X ** 2, X ** 3))

    # 初始化并训练模型
    model = MultipleOutputRegression(basis_functions=3)
    model.fit(X, T)

    # 进行预测
    predictions = model.predict(X)
    print("Predictions:", predictions)
```

此代码定义了一个多输出回归模型类 `MultipleOutputRegression`，并包含训练和预测方法。设计矩阵生成方法 `_design_matrix` 目前使用的是多项式基函数，您可以根据具体需求进行修改。在示例使用部分，生成了一些示例数据并进行了训练和预测 。